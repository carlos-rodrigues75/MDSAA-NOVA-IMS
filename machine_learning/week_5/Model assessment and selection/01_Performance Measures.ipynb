{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Performance Measures\n",
    "\n",
    "* [1 - Regression Problems](#regression)\n",
    "* [2 - Classification Problems](#classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"regression\">\n",
    "\n",
    "## 1. Regression Problems\n",
    "</a>\n",
    "\n",
    "* [1.1. - $R^{2}$ Score](#rsquare)\n",
    "* [1.2. - Adjusted $R^{2}$ Score](#adjusted)\n",
    "* [1.3. - MAE](#mae)\n",
    "* [1.4. - RMSE](#mse)\n",
    "* [1.5. - MedAE](#medae)\n",
    "\n",
    "Import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T09:48:50.595122Z",
     "start_time": "2023-10-04T09:48:50.422298Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 1`__ Import the dataset __Boston.csv__ and define as data the independent variables and target the dependent variable (last column) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T09:48:50.602652Z",
     "start_time": "2023-10-04T09:48:50.595928Z"
    }
   },
   "outputs": [],
   "source": [
    "boston = pd.read_csv(r'./Datasets/Boston.csv')\n",
    "data_boston = boston.iloc[:,:-1]\n",
    "target_boston = boston.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 2`__ By using the method train_test_split from sklearn.model_selection, split your dataset into train(80%) and validation(20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T09:48:51.060242Z",
     "start_time": "2023-10-04T09:48:51.034888Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_boston, \n",
    "                                                    target_boston, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=15, \n",
    "                                                    shuffle=True, \n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 3`__ Create an instance of LinearRegression named as lr with the default parameters and fit to your train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T09:49:42.941843Z",
     "start_time": "2023-10-04T09:49:42.898671Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 4`__ Now that you have your model created, assign the predictions to y_pred, using the method predict()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T09:50:27.820883Z",
     "start_time": "2023-10-04T09:50:27.766146Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 5`__ From __slearn.metrics__ import r2_score, mean_absolute_error, mean_squared_error, median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T09:50:35.708073Z",
     "start_time": "2023-10-04T09:50:35.672179Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, median_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"rsquare\">\n",
    "    \n",
    "### 1.1. $R^{2}$ Score\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score'>sklearn.metrics.r2_score(y_true, y_pred, ... )</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "R^2 (coefficient of determination) regression score function.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). \n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values; <br>\n",
    "_y_pred_: Estimated target values; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 6`__ Check the R^2 score of the model you created previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T09:52:24.561417Z",
     "start_time": "2023-10-04T09:52:24.510371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.692074903865215"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When to use?__ <br>\n",
    "When we want to measure the amount of variance in the target variable that can be explained by our model. <br>\n",
    "It gives the degree of variability in the target variable that is explained by the model or the independent variables. <br>\n",
    "If this value is 0.7, then it means that the independent variables explain 70% of the variation in the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"adjusted\">\n",
    "    \n",
    "### 1.2. Adjusted $R^{2}$ Score\n",
    "\n",
    "</a>\n",
    "\n",
    "There is no direct way to obtain the adjusted R^2 using sklearn, but we can apply the formula:\n",
    "<img src=\"adj_r2.png\" alt=\"Drawing\" style=\"width: 300px;\"/> <br>\n",
    "\n",
    "\n",
    "where n stands for the sample size and p for the number of the regressors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 7`__ Calculate the Adjusted R^2 Score for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T09:57:58.071481Z",
     "start_time": "2023-10-04T09:57:58.027881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.64658596920894"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO IT\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "n = len(y_val)\n",
    "p = len(X_train.columns)\n",
    "\n",
    "def adj_r2(r2,n,p):\n",
    "    return 1-(1-r2)*(n-1)/(n-p-1)\n",
    "\n",
    "adj_r2(r2,n,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When to use?__ <br>\n",
    "When we want to measure the amount of variance in the target variable that can be explained by our model. <br>\n",
    "This is a form of R-squared that is adjusted for the number of terms in the model. <br>\n",
    "As you add independent variables to the model, the adjusted $R^2$\n",
    "  will increase only if these variables truly improve the fit. If an independent variable is not useful, it will have little impact on the adjusted $R^2$\n",
    "\n",
    "__Then what is the advantage of adjusted $R^{2}$?__ <br>\n",
    "\n",
    "When multiple linear regression models are built, say with forward addition method, at each iteration when an independent variable is added, the R squared value will keep increasing, but the adjusted R square will only increase when the variable actually affects the dependent variable.\n",
    "\n",
    "In summary, while $R^{2}$\n",
    "  measures the overall explanatory power of the model, __adjusted__ $R^{2}$\n",
    "  takes into account the complexity of the model, penalizing models with many unnecessary independent variables. __Adjusted \n",
    "$R^{2}$__\n",
    "  is often used to select the most appropriate model when considering the inclusion or exclusion of independent variables in a regression analysis.\n",
    "\n",
    "<hline>\n",
    "\n",
    "***\n",
    "    \n",
    "However in some cases we are more interested in quantifying the error in the same measuring unit of the variable:\n",
    "    - we can use metrics like MAE, MSE and MedAE for that.\n",
    "    \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"mae\">\n",
    "    \n",
    "### 1.3. MAE (Mean absolute error)\n",
    "\n",
    "</a>\n",
    "\n",
    "<img src=\"mae.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "__`Step 8`__ Check the MAE of the model you created previously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error'>sklearn.metrics.mean_absolute_error(y_true, y_pred, ... )</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Mean absolute error regression loss.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "Best possible value is 0.0. MAE is always non-negative.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values; <br>\n",
    "_y_pred_: Estimated target values; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T09:58:12.296713Z",
     "start_time": "2023-10-04T09:58:12.256977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "3.6860868233802537"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When to use?__ <br>\n",
    "It measures the average magnitude of the errors in a set of predictions, without considering their direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"mse\">\n",
    "    \n",
    "### 1.4. RMSE (Root Mean squared error)\n",
    "\n",
    "</a>\n",
    "\n",
    "<img src=\"rmse.png\" alt=\"Drawing\" style=\"width: 250px;\"/>\n",
    "\n",
    "<!-- __`Step 9`__ Check the RMSE of the model you created previously -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error'>sklearn.metrics.mean_squared_error(y_true, y_pred, ... )</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Mean absolute error regression loss.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "Best possible value is 0.0. MSE is always non-negative.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values; <br>\n",
    "_y_pred_: Estimated target values; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:01:18.139565Z",
     "start_time": "2023-10-04T10:01:18.098415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "23.812245465080633"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_pred, squared = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When to use?__ <br>\n",
    "Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. This means the RMSE should be more useful when large errors are particularly undesirable.\n",
    "\n",
    "__MAE vs. RMSE__ <br>\n",
    "RMSE has the benefit of penalizing large errors more so can be more appropriate in some cases, for example, if being off by 20 is more than twice as bad as being off by 10. But if being off by 20 is just twice as bad as being off by 10, then MAE is more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"medae\">\n",
    "    \n",
    "### 1.5. MedAE (Median absolute error)\n",
    "\n",
    "</a>\n",
    "\n",
    "__`Step 10`__ Check the MedAE score of the model you created previously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.median_absolute_error'>sklearn.metrics.median_absolute_error(y_true, y_pred, ... )</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Median absolute error regression loss\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "Best possible value is 0.0. MedAE is always non-negative.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values; <br>\n",
    "_y_pred_: Estimated target values; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:02:11.936989Z",
     "start_time": "2023-10-04T10:02:11.895025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "2.8209646896270435"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_absolute_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When to use?__ <br>\n",
    "Using the median instead of the mean implies that we are ignoring the outliers.This makes it a better choice when your dataset contains observations that significantly deviate from the typical pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"classification\">\n",
    "\n",
    "## 2. Classification Problems\n",
    "</a>\n",
    "\n",
    "* [2.1. - The confusion matrix](#confusion)\n",
    "* [2.2. - The accuracy Score](#accuracy)\n",
    "* [2.3. - The precision](#precision)\n",
    "* [2.4. - The recall](#recall)\n",
    "* [2.5. - The F1 Score](#f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 11`__ Import the needed libraries to apply logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:03:29.204823Z",
     "start_time": "2023-10-04T10:03:29.172707Z"
    }
   },
   "outputs": [],
   "source": [
    "# DO IT\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 12`__ Import the dataset __final_tugas.csv__ and define the independent variables as __data__ and the dependent variable ('DepVar') as __target__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:03:33.283053Z",
     "start_time": "2023-10-04T10:03:33.226636Z"
    }
   },
   "outputs": [],
   "source": [
    "tugas = pd.read_csv(r'./Datasets/final_tugas.csv')\n",
    "data_tugas = tugas.drop(['DepVar'], axis=1)\n",
    "target_tugas = tugas['DepVar']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 13`__ By using the method train_test_split from sklearn.model_selection, split your dataset into train(80%) and validation(20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:03:43.044971Z",
     "start_time": "2023-10-04T10:03:43.005592Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data_tugas, \n",
    "                                                  target_tugas, \n",
    "                                                  test_size = 0.2, \n",
    "                                                  random_state=5, \n",
    "                                                  stratify = target_tugas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 14`__ Create an instance of LogisticRegression named as __log_model__ with the default parameters and fit to your train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:03:43.746531Z",
     "start_time": "2023-10-04T10:03:43.718285Z"
    }
   },
   "outputs": [],
   "source": [
    "log_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:03:44.303210Z",
     "start_time": "2023-10-04T10:03:43.997030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression()",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 15`__ Now that you have your model created, assign the predictions to y_pred, using the method predict()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:04:37.387968Z",
     "start_time": "2023-10-04T10:04:37.298805Z"
    }
   },
   "outputs": [],
   "source": [
    "# DO IT\n",
    "y_pred = log_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 16`__ From __slearn.metrics__ import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics used for classification differ from the ones used for regression. <br>The sklearn library offers a wide range of metrics for this situation. We are going to see the most used ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:04:40.951494Z",
     "start_time": "2023-10-04T10:04:40.908934Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"confusion\">\n",
    "    \n",
    "### 2.1. The confusion matrix\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix'>sklearn.metrics.confusion_matrix(y_true, y_pred, ...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Compute confusion matrix to evaluate the accuracy of a classification\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values.; <br>\n",
    "_y_pred_: Estimated targets as returned by a classifier.; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 17`__ Obtain the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:07:13.311135Z",
     "start_time": "2023-10-04T10:07:13.267872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[455,  10],\n       [ 29,   6]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, y_pred) # Columns = Predicted Value / Rows = Actual Value (or True Value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix in sklearn is presented in the following format: <br>\n",
    "[ [ TN  FP  ] <br>\n",
    "    [ FN  TP ] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"accuracy\">\n",
    "    \n",
    "### 2.2. The accuracy score\n",
    "\n",
    "</a>\n",
    "\n",
    "<img src=\"accuracy.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score'>sklearn.metrics.accuracy_score(y_true, y_pred, normalize=True,...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Accuracy classification score.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "If normalize is True, then the best performance is 1. When normalize = False, then the best performance is the number of samples.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values.; <br>\n",
    "_y_pred_: Estimated targets as returned by a classifier.; <br>\n",
    "_normalize_: If False, return the number of correctly classified samples. Otherwise, return the fraction of correctly classified samples. <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 18`__ Get the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:08:10.329877Z",
     "start_time": "2023-10-04T10:08:10.306541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.922"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO IT\n",
    "accuracy_score(y_val, y_pred) # Sum the true values and divide by all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is accuracy always a good option? Let's check with an example:\n",
    "\n",
    "<img src=\"example_1.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "In this case, what is the accuracy?\n",
    "\n",
    "<img src=\"example_2.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "We have an accuracy of 99,1% which is very very high! That is great, right? <br>\n",
    "Well, not really...<br>\n",
    "Imagine that we are testing people potentially with covid... A positive person is actually someone who is sick and carrying a virus that can spread very quickly! The cost of having a misclassified actual positive (or a false negative) is very high!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"precision\">\n",
    "    \n",
    "### 2.3. The precision\n",
    "\n",
    "</a>\n",
    "\n",
    "<img src=\"precision.png\" alt=\"Drawing\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score'>sklearn.metrics.precision_score(y_true, y_pred, ...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Compute the precision.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "The best value is 1, and the worst value is 0.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values.; <br>\n",
    "_y_pred_: Estimated targets as returned by a classifier.; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 19`__ Get the precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:11:07.846496Z",
     "start_time": "2023-10-04T10:11:07.792382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.375"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the confusion matrix, we can verify that precision is only concerned to the predicted values that were considered positive:\n",
    "    \n",
    "<img src=\"example_3.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "So precision gives us how precise / accurate our model is out of those predicted positive, how many of them are actual positive.\n",
    "\n",
    "__When to use?__\n",
    "\n",
    "`When the cost of False Positives is high.` <br>\n",
    "For example, in email spam detection, where a negative is considered not spam and a positive is a spam email. <br>\n",
    "A false positive will be an email that is considered spam when in reality it was not - the user will loose potentially importante information if the precision is not high in the spam detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"recall\">\n",
    "    \n",
    "### 2.4. The recall\n",
    "\n",
    "</a>\n",
    "<img src=\"recall.png\" alt=\"Drawing\" style=\"width: 180px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.recall_score'>sklearn.metrics.recall_score(y_true, y_pred, ...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Compute the recall.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "The best value is 1 and the worst value is 0.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values.; <br>\n",
    "_y_pred_: Estimated targets as returned by a classifier.; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 20`__ Get the recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:11:10.803553Z",
     "start_time": "2023-10-04T10:11:10.767502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.17142857142857143"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the confusion matrix:\n",
    "    \n",
    "<img src=\"example_4.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Recall calculates how many of the actual positives our model is able to capture through labeling it as positive (True positive).\n",
    "\n",
    "__When to use?__\n",
    "\n",
    "`When the cost of False Negatives is high.` <br>\n",
    "For example, in the example we gave before concerning Covid tests. If a sick patient (Actual Positive) does the test and is predicted as not sick (predicted as negative), the risk will be extremely high since the sickness is contagious. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"f1\">\n",
    "    \n",
    "### 2.5. The F1 Score\n",
    "\n",
    "</a>\n",
    "\n",
    "<img src=\"f1.png\" alt=\"Drawing\" style=\"width: 270px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score'>sklearn.metrics.f1_score(y_true, y_pred, ...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Compute the F1 score, also known as balanced F-score or F-measure.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "F1 score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values.; <br>\n",
    "_y_pred_: Estimated targets as returned by a classifier.; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 21`__ Get the F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:12:15.806220Z",
     "start_time": "2023-10-04T10:12:15.774840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.23529411764705876"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When to use?__\n",
    "\n",
    "F1 Score should be used when you want to seek a balance between Precision and Recall and if there is an uneven class distribution (large number of Actual Negatives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 22`__ To evaluate the results, we are going to use also the classification report method. <br>\n",
    "Import __classification_report__ from __sklearn.metrics__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:12:32.225190Z",
     "start_time": "2023-10-04T10:12:32.179802Z"
    }
   },
   "outputs": [],
   "source": [
    "# DO IT\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 23`__ Create  a function named `metrics` that will print the results of the classification report and the confusion matrix for both datasets (train and validation) _(written for you)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:12:38.279738Z",
     "start_time": "2023-10-04T10:12:38.244978Z"
    }
   },
   "outputs": [],
   "source": [
    "def metrics(y_train, pred_train , y_val, pred_val):\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                     TRAIN                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_train, pred_train))\n",
    "    print(confusion_matrix(y_train, pred_train))\n",
    "\n",
    "\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                VALIDATION                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_val, pred_val))\n",
    "    print(confusion_matrix(y_val, pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 24`__ Create an object named __labels_train__ that will containt the predicted values for the train and another one named __labels_val__ that will contain the predicted values for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:12:43.268804Z",
     "start_time": "2023-10-04T10:12:43.221231Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_train = log_model.predict(X_train)\n",
    "labels_val = log_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 25`__ Call the function metrics() defined previously, and define the arguments: <br> (`y_train = y_train`, `pred_train = labels_train` , `y_val = y_val`, `pred_val = labels_val`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-04T10:13:18.806902Z",
     "start_time": "2023-10-04T10:13:18.763648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________________________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1860\n",
      "           1       0.64      0.26      0.37       140\n",
      "\n",
      "    accuracy                           0.94      2000\n",
      "   macro avg       0.79      0.63      0.67      2000\n",
      "weighted avg       0.93      0.94      0.93      2000\n",
      "\n",
      "[[1839   21]\n",
      " [ 103   37]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                                VALIDATION                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       465\n",
      "           1       0.38      0.17      0.24        35\n",
      "\n",
      "    accuracy                           0.92       500\n",
      "   macro avg       0.66      0.57      0.60       500\n",
      "weighted avg       0.90      0.92      0.91       500\n",
      "\n",
      "[[455  10]\n",
      " [ 29   6]]\n"
     ]
    }
   ],
   "source": [
    "# DO IT\n",
    "metrics(y_train, labels_train, y_val, labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources: <br>\n",
    "https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d <br>\n",
    "https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
