{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size=\"6\">Logistic Regression</font><a class=\"anchor\"><a id='toc'></a></b><br>\n",
    "\n",
    "Logistic regression is a classification algorithm used to assign observations to a discrete set of classes. Unlike linear regression which outputs continuous number values, logistic regression transforms its output using the logistic sigmoid function to return a probability value which can then be mapped to two or more discrete classes. The logistic function has the property of being able to map any real value between 0 and 1. The model is represented by:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\sigma(w_0 + w_1x_1 + w_2x_2 + ... + w_nx_n)\n",
    "$$\n",
    "\n",
    "where $\\sigma$ is the logistic sigmoid function given by:\n",
    "\n",
    "$$\n",
    "\\sigma(t) = \\frac{1}{1 + e^{-t}}\n",
    "$$\n",
    "\n",
    "In binary classification problems, the logistic regression model calculates the probability of an event occuring. If the calculated probability is greater than 0.5, the observation is assigned to a discrete class 1. If the calculated probability is less than 0.5, the observation is assigned to a discrete class 0. In this way, logistic regression can be understood as the probability of a certain event based on the values of the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 1`__ - Import the data and pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T09:49:26.174977Z",
     "start_time": "2023-10-11T09:49:25.650022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      Custid  Year_Birth  Dependents     Income  Rcn  Frq      Mnt  Clothes  \\\n0       1003        1991           1   29761.20   69   11    45.76       32   \n1       1004        1956           1   98249.55   10   26   923.52       60   \n2       1006        1983           1   23505.30   65   14    58.24       47   \n3       1007        1970           1   72959.25   73   18   358.80       71   \n4       1009        1941           0  114973.95   75   30  1457.04       38   \n...      ...         ...         ...        ...  ...  ...      ...      ...   \n2495   10989        1996           1   29551.20   41   10    47.84       11   \n2496   10991        1940           0  132566.70   36   46  2320.24       32   \n2497   10993        1955           0   91768.95    1   25   870.48       56   \n2498   10994        1961           1   99085.35    1   28   931.84       68   \n2499   10997        1939           1  132260.10   75   38  1734.72       61   \n\n      Kitchen  SmallAppliances  ...  DepVar  Gender_M  Education_Basic  \\\n0          19               24  ...       0         1                0   \n1          10               19  ...       0         1                0   \n2           2               48  ...       0         0                0   \n3           7               13  ...       0         0                0   \n4           9               35  ...       0         0                0   \n...       ...              ...  ...     ...       ...              ...   \n2495       40               24  ...       0         0                1   \n2496        4               47  ...       0         0                0   \n2497        8               27  ...       0         0                0   \n2498        5               21  ...       0         0                1   \n2499        2               25  ...       0         0                0   \n\n      Education_Graduation  Education_Master  Education_PhD  \\\n0                        1                 0              0   \n1                        0                 1              0   \n2                        0                 0              1   \n3                        1                 0              0   \n4                        1                 0              0   \n...                    ...               ...            ...   \n2495                     0                 0              0   \n2496                     1                 0              0   \n2497                     1                 0              0   \n2498                     0                 0              0   \n2499                     0                 0              0   \n\n      Marital_Status_Divorced  Marital_Status_Married  \\\n0                           0                       1   \n1                           0                       1   \n2                           0                       0   \n3                           0                       0   \n4                           0                       1   \n...                       ...                     ...   \n2495                        0                       0   \n2496                        0                       1   \n2497                        0                       0   \n2498                        0                       1   \n2499                        0                       0   \n\n      Marital_Status_Together  Marital_Status_Widow  \n0                           0                     0  \n1                           0                     0  \n2                           1                     0  \n3                           0                     0  \n4                           0                     0  \n...                       ...                   ...  \n2495                        0                     0  \n2496                        0                     0  \n2497                        1                     0  \n2498                        0                     0  \n2499                        1                     0  \n\n[2500 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Custid</th>\n      <th>Year_Birth</th>\n      <th>Dependents</th>\n      <th>Income</th>\n      <th>Rcn</th>\n      <th>Frq</th>\n      <th>Mnt</th>\n      <th>Clothes</th>\n      <th>Kitchen</th>\n      <th>SmallAppliances</th>\n      <th>...</th>\n      <th>DepVar</th>\n      <th>Gender_M</th>\n      <th>Education_Basic</th>\n      <th>Education_Graduation</th>\n      <th>Education_Master</th>\n      <th>Education_PhD</th>\n      <th>Marital_Status_Divorced</th>\n      <th>Marital_Status_Married</th>\n      <th>Marital_Status_Together</th>\n      <th>Marital_Status_Widow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1003</td>\n      <td>1991</td>\n      <td>1</td>\n      <td>29761.20</td>\n      <td>69</td>\n      <td>11</td>\n      <td>45.76</td>\n      <td>32</td>\n      <td>19</td>\n      <td>24</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1004</td>\n      <td>1956</td>\n      <td>1</td>\n      <td>98249.55</td>\n      <td>10</td>\n      <td>26</td>\n      <td>923.52</td>\n      <td>60</td>\n      <td>10</td>\n      <td>19</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1006</td>\n      <td>1983</td>\n      <td>1</td>\n      <td>23505.30</td>\n      <td>65</td>\n      <td>14</td>\n      <td>58.24</td>\n      <td>47</td>\n      <td>2</td>\n      <td>48</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1007</td>\n      <td>1970</td>\n      <td>1</td>\n      <td>72959.25</td>\n      <td>73</td>\n      <td>18</td>\n      <td>358.80</td>\n      <td>71</td>\n      <td>7</td>\n      <td>13</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1009</td>\n      <td>1941</td>\n      <td>0</td>\n      <td>114973.95</td>\n      <td>75</td>\n      <td>30</td>\n      <td>1457.04</td>\n      <td>38</td>\n      <td>9</td>\n      <td>35</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2495</th>\n      <td>10989</td>\n      <td>1996</td>\n      <td>1</td>\n      <td>29551.20</td>\n      <td>41</td>\n      <td>10</td>\n      <td>47.84</td>\n      <td>11</td>\n      <td>40</td>\n      <td>24</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2496</th>\n      <td>10991</td>\n      <td>1940</td>\n      <td>0</td>\n      <td>132566.70</td>\n      <td>36</td>\n      <td>46</td>\n      <td>2320.24</td>\n      <td>32</td>\n      <td>4</td>\n      <td>47</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2497</th>\n      <td>10993</td>\n      <td>1955</td>\n      <td>0</td>\n      <td>91768.95</td>\n      <td>1</td>\n      <td>25</td>\n      <td>870.48</td>\n      <td>56</td>\n      <td>8</td>\n      <td>27</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2498</th>\n      <td>10994</td>\n      <td>1961</td>\n      <td>1</td>\n      <td>99085.35</td>\n      <td>1</td>\n      <td>28</td>\n      <td>931.84</td>\n      <td>68</td>\n      <td>5</td>\n      <td>21</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2499</th>\n      <td>10997</td>\n      <td>1939</td>\n      <td>1</td>\n      <td>132260.10</td>\n      <td>75</td>\n      <td>38</td>\n      <td>1734.72</td>\n      <td>61</td>\n      <td>2</td>\n      <td>25</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2500 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tugas = pd.read_csv('datasets/final_tugas.csv')\n",
    "tugas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are in a classification scenario, it is important that we consider the proportions of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T09:49:29.008934Z",
     "start_time": "2023-10-11T09:49:28.998433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    2325\n1     175\nName: DepVar, dtype: int64"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tugas.DepVar.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 2`__ - Data partition\n",
    "- Assign all the variables excluding the DepVar to the object `data`\n",
    "- Assign the dependent variable to the object `target`\n",
    "- Import the needed library to make the partition of the dataset\n",
    "- Split the data and the target to X_train, X_test, y_train, y_test, where `test_size` should be equal to 0.2, `random_state` equal to 5 the `stratify` equal to `target`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T09:52:43.791073Z",
     "start_time": "2023-10-11T09:52:43.780620Z"
    }
   },
   "outputs": [],
   "source": [
    "data = tugas.drop(['DepVar'], axis=1)\n",
    "target = tugas['DepVar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T09:52:44.885442Z",
     "start_time": "2023-10-11T09:52:44.270871Z"
    }
   },
   "outputs": [],
   "source": [
    "#make the split here\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T09:52:46.409080Z",
     "start_time": "2023-10-11T09:52:46.400175Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data,target, test_size=0.2, random_state=5, stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 3`__ - Import the model and create an instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html'>sklearn.linear_model.LogisticRegression(fit_intercept=True,...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Applies Logistic Regression classifier.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "*fit_intercept*: whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T09:54:35.917924Z",
     "start_time": "2023-10-11T09:54:35.835982Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 4`__ - Fit the model to the train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html'>sklearn.linear_model.LogisticRegression().fit(X,y,...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Fit logistic model in the training data.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "X : The regressors in my training dataset; <br>\n",
    "y : The target in my training dataset; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T09:55:24.967157Z",
     "start_time": "2023-10-11T09:55:24.892916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression()",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE HERE\n",
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 5`__ - Use the model to predict the labels of the test data. Assign them to **y_pred**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html'>sklearn.linear_model.LogisticRegression().predict(X)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Predict class labels for samples in X.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "X : Samples to predict; <br>\n",
    "...\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T09:56:50.703798Z",
     "start_time": "2023-10-11T09:56:50.678918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = log_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** You can get the actual probabilities of each sample instead of the assigned class using the method `predict_proba()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T09:57:57.606792Z",
     "start_time": "2023-10-11T09:57:57.560721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[9.95583919e-01, 4.41608077e-03],\n       [9.96770454e-01, 3.22954560e-03],\n       [9.83968216e-01, 1.60317840e-02],\n       [3.46966909e-01, 6.53033091e-01],\n       [9.94684619e-01, 5.31538108e-03],\n       [9.88694276e-01, 1.13057239e-02],\n       [9.99174415e-01, 8.25585488e-04],\n       [9.92827846e-01, 7.17215382e-03],\n       [6.78444605e-01, 3.21555395e-01],\n       [9.85968695e-01, 1.40313047e-02],\n       [9.28410324e-01, 7.15896760e-02],\n       [9.98952923e-01, 1.04707722e-03],\n       [9.87820356e-01, 1.21796443e-02],\n       [9.97947370e-01, 2.05262958e-03],\n       [9.98966921e-01, 1.03307936e-03],\n       [9.97300447e-01, 2.69955272e-03],\n       [9.90187322e-01, 9.81267804e-03],\n       [9.94739371e-01, 5.26062907e-03],\n       [8.80736125e-01, 1.19263875e-01],\n       [9.61548210e-01, 3.84517902e-02],\n       [9.98086372e-01, 1.91362777e-03],\n       [9.92777318e-01, 7.22268242e-03],\n       [2.14466014e-01, 7.85533986e-01],\n       [9.83173532e-01, 1.68264683e-02],\n       [4.71285855e-01, 5.28714145e-01],\n       [3.28108734e-01, 6.71891266e-01],\n       [9.63846631e-01, 3.61533693e-02],\n       [9.97411172e-01, 2.58882833e-03],\n       [9.97937221e-01, 2.06277881e-03],\n       [9.60471475e-01, 3.95285253e-02],\n       [9.52710921e-01, 4.72890790e-02],\n       [9.91281799e-01, 8.71820070e-03],\n       [9.93933010e-01, 6.06698974e-03],\n       [9.97301185e-01, 2.69881456e-03],\n       [9.82434446e-01, 1.75655541e-02],\n       [8.74074661e-01, 1.25925339e-01],\n       [9.92601576e-01, 7.39842413e-03],\n       [9.94052666e-01, 5.94733383e-03],\n       [9.62449917e-01, 3.75500827e-02],\n       [9.02272798e-01, 9.77272020e-02],\n       [8.79059371e-01, 1.20940629e-01],\n       [9.91881898e-01, 8.11810176e-03],\n       [9.40330501e-01, 5.96694987e-02],\n       [8.68056182e-01, 1.31943818e-01],\n       [9.96726986e-01, 3.27301444e-03],\n       [9.90508691e-01, 9.49130920e-03],\n       [8.70201059e-01, 1.29798941e-01],\n       [9.98480098e-01, 1.51990248e-03],\n       [9.97839354e-01, 2.16064639e-03],\n       [9.99415585e-01, 5.84414639e-04],\n       [9.98106696e-01, 1.89330372e-03],\n       [9.90407501e-01, 9.59249918e-03],\n       [9.99139800e-01, 8.60199816e-04],\n       [9.82626312e-01, 1.73736879e-02],\n       [9.97216520e-01, 2.78348030e-03],\n       [9.78371715e-01, 2.16282854e-02],\n       [9.70592415e-01, 2.94075853e-02],\n       [9.95260684e-01, 4.73931603e-03],\n       [9.94823513e-01, 5.17648701e-03],\n       [9.96978349e-01, 3.02165065e-03],\n       [7.94819825e-01, 2.05180175e-01],\n       [9.95227231e-01, 4.77276920e-03],\n       [9.64046158e-01, 3.59538425e-02],\n       [9.99181844e-01, 8.18155547e-04],\n       [8.01560592e-01, 1.98439408e-01],\n       [8.48585360e-01, 1.51414640e-01],\n       [9.92934508e-01, 7.06549233e-03],\n       [9.87118309e-01, 1.28816910e-02],\n       [9.81057020e-01, 1.89429800e-02],\n       [4.70605455e-01, 5.29394545e-01],\n       [9.98257985e-01, 1.74201538e-03],\n       [9.93792882e-01, 6.20711798e-03],\n       [9.98769668e-01, 1.23033242e-03],\n       [9.12175719e-01, 8.78242813e-02],\n       [9.46250571e-01, 5.37494290e-02],\n       [9.96926545e-01, 3.07345501e-03],\n       [9.08343989e-01, 9.16560106e-02],\n       [8.10472879e-01, 1.89527121e-01],\n       [9.93647042e-01, 6.35295790e-03],\n       [9.97523512e-01, 2.47648826e-03],\n       [9.88906376e-01, 1.10936245e-02],\n       [9.63340469e-01, 3.66595310e-02],\n       [9.92620074e-01, 7.37992649e-03],\n       [9.98754337e-01, 1.24566292e-03],\n       [9.98070092e-01, 1.92990846e-03],\n       [9.76893499e-01, 2.31065009e-02],\n       [7.74214205e-01, 2.25785795e-01],\n       [8.93800297e-01, 1.06199703e-01],\n       [9.19163709e-01, 8.08362905e-02],\n       [9.97273278e-01, 2.72672196e-03],\n       [9.79406607e-01, 2.05933926e-02],\n       [8.70510571e-01, 1.29489429e-01],\n       [9.95942758e-01, 4.05724156e-03],\n       [9.98232396e-01, 1.76760436e-03],\n       [9.95004403e-01, 4.99559661e-03],\n       [9.97752127e-01, 2.24787315e-03],\n       [7.69886729e-01, 2.30113271e-01],\n       [9.99023097e-01, 9.76902915e-04],\n       [9.98734204e-01, 1.26579637e-03],\n       [9.99324427e-01, 6.75573002e-04],\n       [9.98910135e-01, 1.08986452e-03],\n       [9.80589237e-01, 1.94107627e-02],\n       [9.78575028e-01, 2.14249718e-02],\n       [9.97214312e-01, 2.78568781e-03],\n       [9.99197743e-01, 8.02257208e-04],\n       [9.65025202e-01, 3.49747983e-02],\n       [9.82622322e-01, 1.73776780e-02],\n       [9.99116857e-01, 8.83143125e-04],\n       [9.95421453e-01, 4.57854711e-03],\n       [9.93472148e-01, 6.52785229e-03],\n       [3.37991977e-01, 6.62008023e-01],\n       [5.14661026e-01, 4.85338974e-01],\n       [9.94609924e-01, 5.39007590e-03],\n       [9.90428681e-01, 9.57131861e-03],\n       [6.66306265e-01, 3.33693735e-01],\n       [9.94597738e-01, 5.40226160e-03],\n       [9.48296372e-01, 5.17036285e-02],\n       [9.98317158e-01, 1.68284212e-03],\n       [9.95591645e-01, 4.40835540e-03],\n       [9.97856062e-01, 2.14393753e-03],\n       [9.91895712e-01, 8.10428763e-03],\n       [8.53018693e-01, 1.46981307e-01],\n       [9.97280956e-01, 2.71904354e-03],\n       [9.99030263e-01, 9.69737342e-04],\n       [9.98257966e-01, 1.74203355e-03],\n       [9.95427915e-01, 4.57208475e-03],\n       [9.77887916e-01, 2.21120844e-02],\n       [9.88149509e-01, 1.18504908e-02],\n       [5.44831817e-01, 4.55168183e-01],\n       [1.45142838e-01, 8.54857162e-01],\n       [9.98720669e-01, 1.27933111e-03],\n       [9.78684740e-01, 2.13152598e-02],\n       [6.41201077e-01, 3.58798923e-01],\n       [9.98282728e-01, 1.71727155e-03],\n       [9.99213526e-01, 7.86474136e-04],\n       [9.90004188e-01, 9.99581221e-03],\n       [8.31895063e-01, 1.68104937e-01],\n       [9.96045174e-01, 3.95482608e-03],\n       [5.05222518e-01, 4.94777482e-01],\n       [9.98711607e-01, 1.28839349e-03],\n       [9.76649495e-01, 2.33505051e-02],\n       [9.98375637e-01, 1.62436273e-03],\n       [9.94876815e-01, 5.12318519e-03],\n       [9.88318830e-01, 1.16811703e-02],\n       [9.84615377e-01, 1.53846226e-02],\n       [7.75288429e-01, 2.24711571e-01],\n       [8.73765922e-01, 1.26234078e-01],\n       [9.68295019e-01, 3.17049810e-02],\n       [8.98480066e-01, 1.01519934e-01],\n       [9.24168494e-01, 7.58315062e-02],\n       [9.90358724e-01, 9.64127602e-03],\n       [9.45290891e-01, 5.47091094e-02],\n       [7.61667099e-01, 2.38332901e-01],\n       [6.33319336e-01, 3.66680664e-01],\n       [9.97400798e-01, 2.59920176e-03],\n       [9.98487974e-01, 1.51202644e-03],\n       [8.46360504e-01, 1.53639496e-01],\n       [9.73890232e-01, 2.61097681e-02],\n       [6.48909702e-01, 3.51090298e-01],\n       [9.96547407e-01, 3.45259283e-03],\n       [9.97076294e-01, 2.92370576e-03],\n       [9.96398819e-01, 3.60118093e-03],\n       [9.13390753e-01, 8.66092474e-02],\n       [9.05582526e-01, 9.44174736e-02],\n       [9.95898148e-01, 4.10185194e-03],\n       [9.95102228e-01, 4.89777164e-03],\n       [9.98260459e-01, 1.73954089e-03],\n       [8.61785478e-01, 1.38214522e-01],\n       [9.74170696e-01, 2.58293043e-02],\n       [9.49778668e-01, 5.02213316e-02],\n       [9.98218934e-01, 1.78106649e-03],\n       [9.97979146e-01, 2.02085414e-03],\n       [9.98810859e-01, 1.18914142e-03],\n       [9.93647576e-01, 6.35242411e-03],\n       [9.98880670e-01, 1.11932984e-03],\n       [9.69494234e-01, 3.05057662e-02],\n       [9.95894981e-01, 4.10501905e-03],\n       [9.98128016e-01, 1.87198399e-03],\n       [3.23764775e-01, 6.76235225e-01],\n       [9.98122464e-01, 1.87753600e-03],\n       [9.92116170e-01, 7.88383050e-03],\n       [9.96896721e-01, 3.10327913e-03],\n       [9.87441822e-01, 1.25581780e-02],\n       [9.98133992e-01, 1.86600774e-03],\n       [9.98426681e-01, 1.57331910e-03],\n       [9.99135329e-01, 8.64670844e-04],\n       [9.93670421e-01, 6.32957950e-03],\n       [9.98761745e-01, 1.23825518e-03],\n       [7.66336703e-01, 2.33663297e-01],\n       [9.98714305e-01, 1.28569494e-03],\n       [9.99468078e-01, 5.31921557e-04],\n       [9.77179830e-01, 2.28201700e-02],\n       [9.44242429e-01, 5.57575706e-02],\n       [9.76336914e-01, 2.36630856e-02],\n       [9.99189751e-01, 8.10248540e-04],\n       [9.18818357e-01, 8.11816428e-02],\n       [5.04332160e-01, 4.95667840e-01],\n       [9.96292721e-01, 3.70727852e-03],\n       [9.99381184e-01, 6.18815623e-04],\n       [9.98067168e-01, 1.93283218e-03],\n       [9.62989073e-01, 3.70109273e-02],\n       [9.95679708e-01, 4.32029209e-03],\n       [9.96739869e-01, 3.26013143e-03],\n       [9.72718526e-01, 2.72814738e-02],\n       [9.98353920e-01, 1.64608040e-03],\n       [9.81415158e-01, 1.85848419e-02],\n       [6.20667557e-01, 3.79332443e-01],\n       [9.71601908e-01, 2.83980921e-02],\n       [9.97792916e-01, 2.20708373e-03],\n       [9.93280998e-01, 6.71900232e-03],\n       [9.95277260e-01, 4.72274012e-03],\n       [9.97108386e-01, 2.89161404e-03],\n       [9.32280020e-01, 6.77199802e-02],\n       [9.95240875e-01, 4.75912458e-03],\n       [3.93996302e-01, 6.06003698e-01],\n       [9.22159257e-01, 7.78407433e-02],\n       [9.91702756e-01, 8.29724449e-03],\n       [9.86485780e-01, 1.35142201e-02],\n       [9.56576026e-01, 4.34239735e-02],\n       [9.33135222e-01, 6.68647781e-02],\n       [9.99332514e-01, 6.67486341e-04],\n       [9.97081766e-01, 2.91823420e-03],\n       [5.57994652e-01, 4.42005348e-01],\n       [9.98848546e-01, 1.15145350e-03],\n       [9.79385632e-01, 2.06143679e-02],\n       [9.96899183e-01, 3.10081682e-03],\n       [9.42909013e-01, 5.70909868e-02],\n       [9.45642083e-01, 5.43579165e-02],\n       [9.98510549e-01, 1.48945125e-03],\n       [9.76885458e-01, 2.31145417e-02],\n       [9.88000010e-01, 1.19999902e-02],\n       [9.98665541e-01, 1.33445887e-03],\n       [9.98022717e-01, 1.97728276e-03],\n       [9.28603926e-01, 7.13960739e-02],\n       [9.70766649e-01, 2.92333508e-02],\n       [1.50745398e-01, 8.49254602e-01],\n       [9.96726714e-01, 3.27328616e-03],\n       [9.58503296e-01, 4.14967037e-02],\n       [9.98115851e-01, 1.88414878e-03],\n       [9.52857746e-01, 4.71422540e-02],\n       [7.24343414e-01, 2.75656586e-01],\n       [8.81206975e-01, 1.18793025e-01],\n       [9.98862115e-01, 1.13788458e-03],\n       [9.95832807e-01, 4.16719325e-03],\n       [9.61270032e-01, 3.87299684e-02],\n       [9.83722221e-01, 1.62777793e-02],\n       [9.93428309e-01, 6.57169141e-03],\n       [9.22678376e-01, 7.73216235e-02],\n       [9.94173232e-01, 5.82676750e-03],\n       [9.38841048e-01, 6.11589519e-02],\n       [6.89450663e-01, 3.10549337e-01],\n       [9.60211584e-01, 3.97884161e-02],\n       [9.97693104e-01, 2.30689638e-03],\n       [9.45992288e-01, 5.40077119e-02],\n       [9.86061708e-01, 1.39382922e-02],\n       [9.79530247e-01, 2.04697533e-02],\n       [9.98401404e-01, 1.59859613e-03],\n       [9.88315770e-01, 1.16842301e-02],\n       [9.98872502e-01, 1.12749775e-03],\n       [9.97548474e-01, 2.45152646e-03],\n       [9.92625020e-01, 7.37498034e-03],\n       [9.89295391e-01, 1.07046089e-02],\n       [9.96081245e-01, 3.91875482e-03],\n       [9.98175477e-01, 1.82452283e-03],\n       [9.04660558e-01, 9.53394424e-02],\n       [9.57502736e-01, 4.24972636e-02],\n       [9.73764185e-01, 2.62358155e-02],\n       [9.99131313e-01, 8.68686923e-04],\n       [9.77935292e-01, 2.20647075e-02],\n       [9.98848984e-01, 1.15101622e-03],\n       [9.97963947e-01, 2.03605341e-03],\n       [7.18408196e-01, 2.81591804e-01],\n       [5.00355828e-01, 4.99644172e-01],\n       [9.97112336e-01, 2.88766352e-03],\n       [9.99406226e-01, 5.93773615e-04],\n       [9.79522714e-01, 2.04772864e-02],\n       [9.68413303e-01, 3.15866970e-02],\n       [9.88521897e-01, 1.14781030e-02],\n       [8.31791306e-01, 1.68208694e-01],\n       [9.98377101e-01, 1.62289868e-03],\n       [9.97870233e-01, 2.12976712e-03],\n       [9.87596324e-01, 1.24036764e-02],\n       [9.97636478e-01, 2.36352250e-03],\n       [9.98784705e-01, 1.21529499e-03],\n       [9.26764699e-01, 7.32353008e-02],\n       [9.91245304e-01, 8.75469624e-03],\n       [9.98443674e-01, 1.55632613e-03],\n       [9.38535959e-01, 6.14640415e-02],\n       [8.93791712e-01, 1.06208288e-01],\n       [9.94599379e-01, 5.40062062e-03],\n       [3.70081714e-01, 6.29918286e-01],\n       [9.60634646e-01, 3.93653541e-02],\n       [9.49716041e-01, 5.02839587e-02],\n       [9.94138856e-01, 5.86114433e-03],\n       [9.96298626e-01, 3.70137374e-03],\n       [9.86430701e-01, 1.35692992e-02],\n       [9.99444435e-01, 5.55565015e-04],\n       [5.23670063e-01, 4.76329937e-01],\n       [9.62235250e-01, 3.77647499e-02],\n       [9.94996057e-01, 5.00394269e-03],\n       [9.47415668e-01, 5.25843321e-02],\n       [9.45932089e-01, 5.40679105e-02],\n       [9.64617486e-01, 3.53825145e-02],\n       [9.60078583e-01, 3.99214173e-02],\n       [9.95535101e-01, 4.46489910e-03],\n       [9.92606259e-01, 7.39374123e-03],\n       [9.60015508e-01, 3.99844916e-02],\n       [9.98990117e-01, 1.00988329e-03],\n       [8.00074467e-01, 1.99925533e-01],\n       [8.57542175e-01, 1.42457825e-01],\n       [6.87732329e-01, 3.12267671e-01],\n       [9.96425438e-01, 3.57456205e-03],\n       [8.53593987e-01, 1.46406013e-01],\n       [9.72026625e-01, 2.79733751e-02],\n       [9.70735403e-01, 2.92645970e-02],\n       [9.80897960e-01, 1.91020400e-02],\n       [9.20687815e-01, 7.93121851e-02],\n       [9.30928515e-01, 6.90714853e-02],\n       [9.98129017e-01, 1.87098341e-03],\n       [7.68738445e-01, 2.31261555e-01],\n       [9.98561102e-01, 1.43889832e-03],\n       [9.97376979e-01, 2.62302149e-03],\n       [9.98331681e-01, 1.66831946e-03],\n       [9.17091680e-01, 8.29083197e-02],\n       [9.75480375e-01, 2.45196245e-02],\n       [8.45692348e-01, 1.54307652e-01],\n       [8.03513643e-01, 1.96486357e-01],\n       [9.88593596e-01, 1.14064038e-02],\n       [8.60531034e-01, 1.39468966e-01],\n       [9.96960546e-01, 3.03945366e-03],\n       [9.98271772e-01, 1.72822752e-03],\n       [9.98699565e-01, 1.30043488e-03],\n       [9.98333914e-01, 1.66608570e-03],\n       [9.94836668e-01, 5.16333183e-03],\n       [9.98769186e-01, 1.23081368e-03],\n       [6.99282081e-01, 3.00717919e-01],\n       [9.64920935e-01, 3.50790646e-02],\n       [9.85219880e-01, 1.47801200e-02],\n       [8.66625728e-01, 1.33374272e-01],\n       [9.98732525e-01, 1.26747453e-03],\n       [7.14473130e-01, 2.85526870e-01],\n       [9.89553224e-01, 1.04467759e-02],\n       [9.94631355e-01, 5.36864525e-03],\n       [9.28802898e-01, 7.11971020e-02],\n       [9.69397090e-01, 3.06029098e-02],\n       [3.44448463e-01, 6.55551537e-01],\n       [9.99421988e-01, 5.78011892e-04],\n       [9.95831783e-01, 4.16821697e-03],\n       [9.96252311e-01, 3.74768850e-03],\n       [9.95941010e-01, 4.05899043e-03],\n       [9.60847641e-01, 3.91523588e-02],\n       [9.90103590e-01, 9.89640958e-03],\n       [9.90083984e-01, 9.91601573e-03],\n       [8.93311868e-01, 1.06688132e-01],\n       [9.97210437e-01, 2.78956266e-03],\n       [9.77642013e-01, 2.23579874e-02],\n       [9.86155446e-01, 1.38445540e-02],\n       [9.96772555e-01, 3.22744501e-03],\n       [9.92950683e-01, 7.04931722e-03],\n       [8.70363082e-01, 1.29636918e-01],\n       [8.77827166e-01, 1.22172834e-01],\n       [9.98020539e-01, 1.97946095e-03],\n       [9.98151584e-01, 1.84841586e-03],\n       [9.96646534e-01, 3.35346622e-03],\n       [9.95232431e-01, 4.76756879e-03],\n       [9.38810258e-01, 6.11897415e-02],\n       [9.82156434e-01, 1.78435658e-02],\n       [5.68498451e-01, 4.31501549e-01],\n       [9.98455838e-01, 1.54416237e-03],\n       [9.88547489e-01, 1.14525114e-02],\n       [9.86791808e-01, 1.32081921e-02],\n       [9.85066353e-01, 1.49336467e-02],\n       [8.34707417e-01, 1.65292583e-01],\n       [9.87202420e-01, 1.27975800e-02],\n       [6.06971888e-01, 3.93028112e-01],\n       [9.38367452e-01, 6.16325483e-02],\n       [9.92707383e-01, 7.29261684e-03],\n       [9.95806403e-01, 4.19359685e-03],\n       [9.88529899e-01, 1.14701010e-02],\n       [9.95665833e-01, 4.33416672e-03],\n       [9.52831470e-01, 4.71685303e-02],\n       [9.96429165e-01, 3.57083526e-03],\n       [9.98708275e-01, 1.29172502e-03],\n       [8.80563601e-01, 1.19436399e-01],\n       [9.61306965e-01, 3.86930349e-02],\n       [8.96402267e-01, 1.03597733e-01],\n       [9.18903523e-01, 8.10964766e-02],\n       [9.97390254e-01, 2.60974618e-03],\n       [9.89852879e-01, 1.01471207e-02],\n       [9.83478969e-01, 1.65210307e-02],\n       [9.05541070e-01, 9.44589303e-02],\n       [9.89523481e-01, 1.04765188e-02],\n       [3.24924475e-01, 6.75075525e-01],\n       [3.09744318e-01, 6.90255682e-01],\n       [9.97179114e-01, 2.82088642e-03],\n       [9.81814518e-01, 1.81854816e-02],\n       [9.98963031e-01, 1.03696931e-03],\n       [9.98678248e-01, 1.32175208e-03],\n       [9.86285041e-01, 1.37149589e-02],\n       [8.70663745e-01, 1.29336255e-01],\n       [9.96536070e-01, 3.46393039e-03],\n       [9.94629609e-01, 5.37039106e-03],\n       [9.97963370e-01, 2.03663003e-03],\n       [9.82081449e-01, 1.79185515e-02],\n       [9.05283351e-01, 9.47166494e-02],\n       [9.92679519e-01, 7.32048106e-03],\n       [9.98963289e-01, 1.03671139e-03],\n       [9.97146936e-01, 2.85306356e-03],\n       [9.86981627e-01, 1.30183725e-02],\n       [7.69523306e-01, 2.30476694e-01],\n       [7.43078184e-01, 2.56921816e-01],\n       [9.91551542e-01, 8.44845785e-03],\n       [9.94523316e-01, 5.47668353e-03],\n       [9.99221472e-01, 7.78528386e-04],\n       [8.21869517e-01, 1.78130483e-01],\n       [9.74740107e-01, 2.52598929e-02],\n       [9.90759106e-01, 9.24089395e-03],\n       [9.90329182e-01, 9.67081823e-03],\n       [9.98465648e-01, 1.53435174e-03],\n       [9.79214534e-01, 2.07854664e-02],\n       [9.83881878e-01, 1.61181218e-02],\n       [7.09384720e-01, 2.90615280e-01],\n       [7.57477688e-01, 2.42522312e-01],\n       [9.71123094e-01, 2.88769064e-02],\n       [9.98904686e-01, 1.09531388e-03],\n       [9.77878199e-01, 2.21218008e-02],\n       [9.95682912e-01, 4.31708767e-03],\n       [9.98948728e-01, 1.05127176e-03],\n       [9.98384620e-01, 1.61538012e-03],\n       [9.26544538e-01, 7.34554619e-02],\n       [9.93651169e-01, 6.34883142e-03],\n       [9.82448940e-01, 1.75510597e-02],\n       [9.98717997e-01, 1.28200273e-03],\n       [9.66546445e-01, 3.34535545e-02],\n       [6.33964595e-01, 3.66035405e-01],\n       [9.91981005e-01, 8.01899487e-03],\n       [9.96303398e-01, 3.69660188e-03],\n       [9.95149289e-01, 4.85071148e-03],\n       [9.94669416e-01, 5.33058441e-03],\n       [9.99028158e-01, 9.71841787e-04],\n       [9.98074692e-01, 1.92530834e-03],\n       [9.99220835e-01, 7.79165378e-04],\n       [9.93439661e-01, 6.56033867e-03],\n       [9.73115314e-01, 2.68846859e-02],\n       [9.87123065e-01, 1.28769353e-02],\n       [9.99249427e-01, 7.50573322e-04],\n       [9.97815612e-01, 2.18438844e-03],\n       [8.79222530e-01, 1.20777470e-01],\n       [9.00876459e-01, 9.91235408e-02],\n       [9.58516717e-01, 4.14832833e-02],\n       [9.99230707e-01, 7.69293036e-04],\n       [9.96371463e-01, 3.62853728e-03],\n       [9.93384163e-01, 6.61583717e-03],\n       [9.37352945e-01, 6.26470547e-02],\n       [9.73967093e-01, 2.60329072e-02],\n       [8.78260349e-01, 1.21739651e-01],\n       [8.71605881e-01, 1.28394119e-01],\n       [9.96742670e-01, 3.25732987e-03],\n       [9.98396894e-01, 1.60310624e-03],\n       [9.58686844e-01, 4.13131559e-02],\n       [9.98900490e-01, 1.09951007e-03],\n       [9.89426028e-01, 1.05739717e-02],\n       [9.98703159e-01, 1.29684054e-03],\n       [9.97239420e-01, 2.76057957e-03],\n       [9.92035622e-01, 7.96437847e-03],\n       [9.45996704e-01, 5.40032957e-02],\n       [9.51245423e-01, 4.87545775e-02],\n       [9.99081408e-01, 9.18591737e-04],\n       [9.52677055e-01, 4.73229451e-02],\n       [9.97979129e-01, 2.02087097e-03],\n       [9.43211788e-01, 5.67882122e-02],\n       [9.99121994e-01, 8.78006434e-04],\n       [8.55392652e-01, 1.44607348e-01],\n       [9.50410898e-01, 4.95891023e-02],\n       [8.11451127e-01, 1.88548873e-01],\n       [9.94403633e-01, 5.59636659e-03],\n       [9.33593478e-01, 6.64065220e-02],\n       [9.97766982e-01, 2.23301754e-03],\n       [9.81310941e-01, 1.86890593e-02],\n       [8.44867027e-01, 1.55132973e-01],\n       [9.98803781e-01, 1.19621941e-03],\n       [9.98428709e-01, 1.57129059e-03],\n       [9.96952581e-01, 3.04741897e-03],\n       [9.95566889e-01, 4.43311069e-03],\n       [9.70391313e-01, 2.96086868e-02],\n       [9.95700138e-01, 4.29986151e-03],\n       [9.98001236e-01, 1.99876400e-03],\n       [9.97267546e-01, 2.73245389e-03],\n       [8.56902189e-01, 1.43097811e-01],\n       [9.96978857e-01, 3.02114277e-03],\n       [9.95095187e-01, 4.90481271e-03],\n       [9.89337484e-01, 1.06625162e-02],\n       [7.29479487e-01, 2.70520513e-01],\n       [2.59150197e-01, 7.40849803e-01],\n       [9.93433090e-01, 6.56691038e-03],\n       [9.90238367e-01, 9.76163327e-03],\n       [9.58149120e-01, 4.18508805e-02],\n       [9.90555102e-01, 9.44489844e-03],\n       [9.26031727e-01, 7.39682726e-02],\n       [2.42605469e-01, 7.57394531e-01]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob = log_model.predict_proba(X_test)\n",
    "pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** In the same way as for the linear regression, you can get the coefficients and intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:00:39.000540Z",
     "start_time": "2023-10-11T10:00:38.991061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 2.80001806e-05, -3.85905571e-03,  4.26737090e-05,\n         1.55298947e-05,  6.00127787e-04,  1.19019723e-03,\n         2.43909462e-03,  1.72590586e-02, -2.65835014e-03,\n        -9.22565389e-03, -3.16836628e-03, -2.52209886e-03,\n         6.01005789e-03, -6.34963795e-03,  8.41784856e-05,\n        -2.33297227e-05,  3.31711416e-06, -1.64116441e-05,\n         3.76034926e-05, -5.67068085e-05,  5.31851429e-05,\n        -5.23352808e-05, -1.06689509e-05, -3.99910604e-06]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 6`__ - Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** Since we are predicting a categorical target (classification) we use other metrics to evaluate our model than if we were solving a regression problem. Also, for the logistic regression the R-squared cannot be obtained in the same way as we obtain it in the linear case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix'>sklearn.metrics.confusion_matrix(y_true, y_pred, ...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Compute confusion matrix to evaluate the accuracy of a classification\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values.; <br>\n",
    "_y_pred_: Estimated targets as returned by a classifier.; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:01:16.088398Z",
     "start_time": "2023-10-11T10:01:16.084235Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:02:22.302691Z",
     "start_time": "2023-10-11T10:02:22.287585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[455,  10],\n       [ 29,   6]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix in sklearn is presented in the following format: <br>\n",
    "[ [ TN  FP  ] <br>\n",
    "    [ FN  TP ] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The accuracy score\n",
    "<img src=\"img/accuracy.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score'>sklearn.metrics.accuracy_score(y_true, y_pred, normalize=True,...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Accuracy classification score.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "If normalize is True, then the best performance is 1. When normalize = False, then the best performance is the number of samples.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values.; <br>\n",
    "_y_pred_: Estimated targets as returned by a classifier.; <br>\n",
    "_normalize_: If False, return the number of correctly classified samples. Otherwise, return the fraction of correctly classified samples. <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:04:36.242332Z",
     "start_time": "2023-10-11T10:04:36.240541Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:04:51.030931Z",
     "start_time": "2023-10-11T10:04:51.011328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.922"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The precision\n",
    "<img src=\"img/precision.png\" alt=\"Drawing\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score'>sklearn.metrics.precision_score(y_true, y_pred, ...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Compute the precision.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "The best value is 1, and the worst value is 0.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values.; <br>\n",
    "_y_pred_: Estimated targets as returned by a classifier.; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:05:04.479712Z",
     "start_time": "2023-10-11T10:05:04.467597Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:05:15.215427Z",
     "start_time": "2023-10-11T10:05:15.196941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.375"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_pred)\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The recall\n",
    "<img src=\"img/recall.png\" alt=\"Drawing\" style=\"width: 180px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.recall_score'>sklearn.metrics.recall_score(y_true, y_pred, ...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Compute the recall.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "The best value is 1 and the worst value is 0.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values.; <br>\n",
    "_y_pred_: Estimated targets as returned by a classifier.; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:07:24.275267Z",
     "start_time": "2023-10-11T10:07:24.257765Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:07:24.564731Z",
     "start_time": "2023-10-11T10:07:24.554259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.17142857142857143"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = recall_score(y_test, y_pred)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The F1 Score\n",
    "<img src=\"img/f1.png\" alt=\"Drawing\" style=\"width: 270px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<a href = 'https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score'>sklearn.metrics.f1_score(y_true, y_pred, ...)</a>\n",
    "\n",
    "__Definition:__ <br>\n",
    "Compute the F1 score, also known as balanced F-score or F-measure.\n",
    "\n",
    "__Interpretation:__ <br>\n",
    "F1 score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "__Parameters:__ <br>\n",
    "_y_true_: Ground truth (correct) target values.; <br>\n",
    "_y_pred_: Estimated targets as returned by a classifier.; <br>\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:09:16.011095Z",
     "start_time": "2023-10-11T10:09:16.008603Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T10:09:24.048743Z",
     "start_time": "2023-10-11T10:09:24.031205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.23529411764705876"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = f1_score(y_test, y_pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
